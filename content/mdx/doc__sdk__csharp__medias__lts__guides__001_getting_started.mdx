---
title: "CPaaS SDK for business communication solutions | Rainbow"
description: "Add chat, conference, real time collaboration and communication (PBX, VoIP, P2P) capabilities, bots and more to your business applications."
type: "sdk"
source: "https://developers.openrainbow.com/doc/sdk/csharp/medias/lts/guides/001_getting_started"
lastSynced: "2026-02-19T22:35:14.177Z"
---
# Documentation

Getting started

LTS release 1.XPubliée le 2024-07-01

# Getting Started

Welcome to the Alcatel-Lucent Enterprise **Rainbow CSharp SDK Medias**.

This SDK can be used as a standalone package without the need of Rainbow Account, Rainbow Server or Rainbow Infrastructure.

This SDK can be used on these platforms: **Windows, MacOs, and Linux**. **Only x64 platforms are supported.**

**Android and iOS are NOT YET supported.**

# Features

It permits to manage Audio and Video streams using:

-   Local / Remote Files
    
-   IP TV, Live Stream Server
    
-   Devices like Webcam, Screen/Monitor, Microphone, Speaker, Headset, ...
    

To access remote streams all this [protocols](https://ffmpeg.org/ffmpeg-all.html#toc-Protocols) are supported.

An Audio and/or Video Stream (whatever its source) is calles a **Media** in this SDK.

A **Media** can be composed of one Audio stream and/or one Video stream.

Using a **Media** it's then possible, for example, to create a Media Player: **Start, Stop, Pause, Resume, Seek actions are possible**.

Using one **Media** or severals, it's then possible to create a **MediaFiltered** using a Video filter and/or an Audio filter.

Video Filter allows to:

-   scale, crop, pad, resize, change fps, add subtitles
    
-   create mosaic, overlay, dynamic mask
    

Audio filter is not yet supported. The **MediaFiltered** will use the Audio stream of the specified **Media**.

On the fly you can change the filter. The Audio/Video stream of the **MediaFiltered** will be updated in consequence without the need to re-start all **Media** used.

# Filter - List, Syntax and Examples

## Filter - List

The list of available **Audio filters** are available [here](https://ffmpeg.org/ffmpeg-all.html#Audio-Filters)

The list of available **Video filters** are available [here](https://ffmpeg.org/ffmpeg-all.html#Video-Filters)

## Filter - Syntax

Same syntax used in FFmpeg can be used in this package.

The best thing to do it's to test first your filter using ffmpeg with a command line using **"-vf"** parameter (to set video filter). The same value can be used as filter in this SDK.

## Filter - Examples

Here some examples than can be used.

### Using only one **Media**

To have video in gray:

```
format=gray
```

To blur the video:

```
avgblur=10
```

To scale the video:

```
scale=400:-2
```

To crop the video:

```
crop=400:400
```

To draw a text on the video:

```
drawtext=text=%{localtime\: %X }:fontcolor=white:fontsize=40:y=(main_h-text_h)/2:x=(main_w-text_w)/2
```

To add subtitles on the video using subtitles from the file "c:\\media\\TOEFLTest.mp4"

```
subtitles=f=c\\:\\\\medias\\\\TOEFLTest.mp4:si=0
```

**Several options can set in same time**, for example, to scale then pad the video:

```
scale=200:-2,pad=320:200:(ow-iw)/2:(oh-ih)/2
```

Here, we blur a zone of a video and add also subtitles:

```
[0:v]crop=400:400,avgblur=10[fg];[0:v][fg]overlay=(main_w-overlay_w)/2:(main_h-overlay_h)/2[blured];[blured]subtitles=f=c\\:\\\\media\\\\TOEFLTest.mp4:si=0
```

### Using two **Medias**

To display two videos streams in one stream. Each video stream is first scaled and padde to a 320x240 stream. Then they are displayed vertically.

```
[0]setpts=PTS-STARTPTS,scale=320:-2,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a0];
[1]setpts=PTS-STARTPTS,scale=320:-2,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a1];
[a0][a1]xstack=inputs=2:layout=0_0|0_h0[out]
```

The first video stream is scaled then overlay on the second one:

```
[0]setpts=PTS-STARTPTS,scale=250:-2[a2];
[1]setpts=PTS-STARTPTS[a1];
[a1][a2]overlay=x=W-w:y=0
```

The first video stream is scaled then using a circle and a mask we ouse it as overlay on the second one:

```
[0]scale=250:-1,geq='st(3,pow(X-(W/2),2)+pow(Y-(H/2),2))\;if(lte(ld(3),pow(min(W/2,H/2),2)),255,0):128:128'[scaledMask];
  [0]scale=250:-1[scaled];
  [scaled][scaledMask]alphamerge[cutout];
  [cutout]setpts=PTS-STARTPTS[a2];
  [1]setpts=PTS-STARTPTS[a1];
  [a1][a2]overlay=x=W-w:y=0
```

### Using more than two **Medias**

Four Video streams are scaled then padded to have a 320x240 output. Then they are used to create a grid of 2x2:

```
[0]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a0];
[1]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a1];
[2]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a2];
[3]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a3];
[a0][a1][a2][a3]xstack=inputs=4:grid=2x2
```

Six Video streams are scaled then padded to have a 320x240 output. Then theyr used to create a grid of 2x3:

```
[0]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a0];
[1]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a1];
[2]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a2];
[3]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a3];
[4]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a4];
[5]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a5];
[a0][a1][a2][a3][a4][a5]xstack=inputs=6:grid=2x3
```

Nine Video streams are scaled then padded to have a 320x240 output. Then theyr used to create a grid of 3x3:

```
[0]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a0];
[1]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a1];
[2]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a2];
[3]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a3];
[4]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a4];
[5]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a5];
[6]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a6];
[7]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a7];
[8]setpts=PTS-STARTPTS,scale=320:-1,pad=320:240:(ow-iw)/2:(oh-ih)/2,format=rgb24[a8];
[a0][a1][a2][a3][a4][a5][a6][a7][a8]xstack=inputs=9:grid=3x3
```

# Full example

A [full example](https://github.com/Rainbow-CPaaS/Rainbow-CSharp-SDK-Samples/tree/master/Medias/Windows/UIForm.Medias) is provided to understand all features of this package.

![](doc/sdk/csharp/medias/lts/guides/images/FormMediaInputStreams-description.png)

# Third-Party Libraries

## Libraries specific for each platform

This SDK is based on:

-   [FFmpeg](https://www.ffmpeg.org/) libraries. **V7.0.1 with shared libraries must be used**
-   [SDL2](https://www.libsdl.org) libraries. **v2.0.22 must be used**

They are available for each platform (Windows, MacOs, and Linux) but you need to get them differently according your environment.

### Windows

#### SDL2 libraries:

Download X64 libraries from here: https://github.com/libsdl-org/SDL/releases/tag/release-2.0.22

Then they must be installed in the same folder that your executable using this SDK.

#### FFmpeg libraries:

Download X64 libraries from here: https://github.com/GyanD/codexffmpeg/releases/tag/7.0.1 (use file [ffmpeg-7.0.1-full\_build-shared.zip](https://github.com/GyanD/codexffmpeg/releases/download/7.0.1/ffmpeg-7.0.1-full_build-shared.zip) )

From this ZIP file only files in folder **bin** are used by the SDK. You can store them on your system where you want but you need to specify this folder when you create an instance of **WebRTCCommunications** object.

Example:

```csharp
String FFMPEG_LIB_PATH = @"C:\ffmpeg-7.0.1-full_build-shared\bin";

Rainbow.Application rbApplication = new Rainbow.Application();
Rainbow.WebRTCCommunications rbWebRTCCommunications =  WebRTCCommunications.CreateInstance(rbApplication, FFMPEG_LIB_PATH);
```

### MacOS

#### SDL2 libraries:

Download X64 libraries from here: https://www.libsdl.org/download-2.0.php

Then they must be installed in the same folder that your executable using this SDK.

#### FFmpeg libraries:

Get x64 libraries using this command line: (adapt it to get v7.0.1)

`sudo apt install ffmpeg`

Then use these command line:

`ffmpeg --version`

You will have an ouput with some details about ffmpeg and about **libdir** or **shlibdir** path.

For example something like this: **\--libdir=/usr/lib/aarch64-linux-gnu** or **\--shlibdir=/usr/lib/aarch64-linux-gnu**

Use this path to create a valide **WebRTCCommunications** object.

Example:

```csharp
String FFMPEG_LIB_PATH = @"/usr/lib/aarch64-linux-gnu";

Rainbow.Application rbApplication = new Rainbow.Application();
Rainbow.WebRTCCommunications rbWebRTCCommunications =  WebRTCCommunications.CreateInstance(rbApplication, FFMPEG_LIB_PATH);
```

### Linux

#### SDL2 libraries:

Get x64 libraries using this command line:

`sudo apt-get install libsdl2-dev`

Then they must be installed in the same folder that your executable using this SDK.

#### FFmpeg libraries:

Get x64 libraries using this command line: (adapt it to get v7.0.1)

`sudo apt install ffmpeg`

Then use these command line:

`ffmpeg --version`

You will have an ouput with some details about ffmpeg and about **libdir** or **shlibdir** path.

For example something like this: **\--libdir=/usr/lib/x86\_64-linux-gnu** or **\--shlibdir=/usr/lib/x86\_64-linux-gnu**

Use this path to create a valide **WebRTCCommunications** object.

Example:

```csharp
String FFMPEG_LIB_PATH = @"/usr/lib/x86_64-linux-gnu";

Rainbow.Application rbApplication = new Rainbow.Application();
Rainbow.WebRTCCommunications rbWebRTCCommunications =  WebRTCCommunications.CreateInstance(rbApplication, FFMPEG_LIB_PATH);
```

### Sur cette page

-   [Filter - List](/docs/sdk/csharp#name-filter---list-77)
-   [Filter - Syntax](/docs/sdk/csharp#name-filter---syntax-86)
-   [Filter - Examples](/docs/sdk/csharp#name-filter---examples-95)
-   [Using only one Media](/docs/sdk/csharp#name-using-only-one-media-101)
-   [Using two Medias](/docs/sdk/csharp#name-using-two-medias-136)
-   [Using more than two Medias](/docs/sdk/csharp#name-using-more-than-two-medias-151)
-   [Libraries specific for each platform](/docs/sdk/csharp#name-libraries-specific-for-each-platform-178)
-   [Windows](/docs/sdk/csharp#name-windows-199)
-   [SDL2 libraries:](/docs/sdk/csharp#name-sdl2-libraries:-202)
-   [FFmpeg libraries:](/docs/sdk/csharp#name-ffmpeg-libraries:-211)
-   [MacOS](/docs/sdk/csharp#name-macos-224)
-   [SDL2 libraries:](/docs/sdk/csharp#name-sdl2-libraries:-227)
-   [FFmpeg libraries:](/docs/sdk/csharp#name-ffmpeg-libraries:-236)
-   [Linux](/docs/sdk/csharp#name-linux-264)
-   [SDL2 libraries:](/docs/sdk/csharp#name-sdl2-libraries:-267)
-   [FFmpeg libraries:](/docs/sdk/csharp#name-ffmpeg-libraries:-279)

---

Ce contenu vous a-t-il été utile ?OuiNon

Feedback